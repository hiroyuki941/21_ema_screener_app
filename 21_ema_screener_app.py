import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import requests
from io import StringIO

# -------------------------------------------------
# 21EMA Screener  ‚Äì  Streamlit Web App (v0.4)
# -------------------------------------------------
# ‚Ä¢ NASDAQ‚Äë100 / Russell2000: Wikipedia & NasdaqTrader „ÅÆ„Åø‰ΩøÁî® (404 URL ÂÆåÂÖ®Êí§ÂªÉ)
# ‚Ä¢ DataFrame ‰ª£ÂÖ•ÊôÇ„ÅÆ ValueError „ÇíÈò≤„Åê„Åü„ÇÅ assign() „Å´Êõ∏„ÅçÊèõ„Åà
# -------------------------------------------------

st.set_page_config(page_title="21EMA Screener", layout="wide")
st.title("üìà 21EMA ÊàêÈï∑Ê†™„Çπ„ÇØ„É™„Éº„Éä„Éº")
st.caption("Êù°‰ª∂Ôºö21EMA‰πñÈõ¢ ¬±5%„ÄÅATR% 3„Äú5%„ÄÅÂá∫Êù•È´ò50Êó•Âπ≥Âùá > 10‰∏áÊ†™„ÄÅMAÈ†ÜÂ∫è„ÉÅ„Çß„ÉÉ„ÇØ")

# -------------------------------------------------
# „ÉÜ„Ç£„ÉÉ„Ç´„ÉºÂèñÂæó„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£
# -------------------------------------------------

def _clean(series: pd.Series) -> list[str]:
    return (
        series.astype(str)
        .str.upper()
        .str.replace(".", "-", regex=False)
        .str.strip()
        .dropna()
        .tolist()
    )

def fetch_wikipedia_tickers(url: str, possible_cols: list[str]) -> list[str]:
    try:
        tables = pd.read_html(url, flavor="lxml")
        for tbl in tables:
            for col in possible_cols:
                if col in tbl.columns:
                    return _clean(tbl[col])
        st.warning(f"‚ö†Ô∏è Wikipedia„Éö„Éº„Ç∏„Å´Âàó„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: {url}")
        return []
    except Exception as e:
        st.warning(f"‚ö†Ô∏è WikipediaÂèñÂæóÂ§±Êïó: {url} ‚Üí {e}")
        st.exception(e)
        return []

def fetch_russell2000() -> list[str]:
    txt_url = "https://www.nasdaqtrader.com/dynamic/SymDir/russell2000.txt"
    try:
        txt = requests.get(txt_url, timeout=10, headers={"User-Agent": "Mozilla/5.0"}).text
        rows = [line.split("|")[0] for line in txt.splitlines() if "|" in line]
        return _clean(pd.Series(rows[1:]))
    except Exception:
        return fetch_wikipedia_tickers("https://en.wikipedia.org/wiki/Russell_2000_Index", ["Ticker", "Symbol"])

# @st.cache_data(show_spinner=False)
def load_ticker_lists() -> list[str]:
    sp500 = fetch_wikipedia_tickers("https://en.wikipedia.org/wiki/List_of_S%26P_500_companies", ["Symbol", "Ticker"])
    nasdaq100 = fetch_wikipedia_tickers("https://en.wikipedia.org/wiki/NASDAQ-100", ["Ticker", "Symbol"])
    russell2000 = fetch_russell2000()

    tickers = sorted(set(sp500 + nasdaq100 + russell2000))
    if not tickers:
        st.error("„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÅÆ„ÉÜ„Ç£„ÉÉ„Ç´„ÉºÂèñÂæó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÁí∞Â¢É„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    return tickers

# -------------------------------------------------
# „ÉÜ„ÇØ„Éã„Ç´„É´ÊåáÊ®ôË®àÁÆó
# -------------------------------------------------

def calculate_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["21EMA"] = df["Close"].ewm(span=21).mean()

    prev_close = df["Close"].shift()
    tr = np.maximum(df["High"] - df["Low"], np.maximum(abs(df["High"] - prev_close), abs(df["Low"] - prev_close)))
    df["ATR_21"] = tr.rolling(window=21, min_periods=1).mean()
    df = df.assign(ATR_pct=(df["ATR_21"] / df["Close"]).mul(100))

    df["10SMA"] = df["Close"].rolling(window=10).mean()
    df["50SMA"] = df["Close"].rolling(window=50).mean()
    df["150SMA"] = df["Close"].rolling(window=150).mean()
    df["200SMA"] = df["Close"].rolling(window=200).mean()
    df["Vol50Avg"] = df["Volume"].rolling(window=50).mean()
    return df

@st.cache_data(show_spinner=False)
def get_data(ticker: str):
    df = yf.download(ticker, period="1y", progress=False, auto_adjust=True, threads=False)
    if df.empty or len(df) < 200:
        return None
    return calculate_technical_indicators(df)

# -------------------------------------------------
# UI
# -------------------------------------------------
ema_min, ema_max = st.slider("21EMA‰πñÈõ¢Áéá (%)", -10.0, 10.0, (-5.0, 5.0), 0.1)
atr_min, atr_max = st.slider("21Êó•ATR%", 0.0, 15.0, (3.0, 5.0), 0.1)
vol_threshold = st.number_input("Âá∫Êù•È´ò (50Êó•Âπ≥Âùá, Ê†™Êï∞)", value=100000, step=10000, format="%d")
run_button = st.button("üîç „Çπ„ÇØ„É™„Éº„Éã„É≥„Ç∞ÂÆüË°å")

# -------------------------------------------------
# „É°„Ç§„É≥Âá¶ÁêÜ
# -------------------------------------------------
if run_button:
    tickers = load_ticker_lists()
    if not tickers:
        st.stop()

    st.info(f"ÂØæË±°„ÉÜ„Ç£„ÉÉ„Ç´„ÉºÊï∞: {len(tickers)} ‰ª∂ ‚Äì „Éá„Éº„ÇøÂèñÂæó„Å´„ÅØÊï∞ÂàÜ„Åã„Åã„ÇãÂ†¥Âêà„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ")
    prog = st.progress(0.0)

    results = []
    for i, tic in enumerate(tickers):
        prog.progress((i + 1) / len(tickers), text=f"{tic} ÂèñÂæó‰∏≠‚Ä¶")
        df = get_data(tic)
        if df is None:
            continue
        row = df.iloc[-1]

        gap_pct = (row["Close"] - row["21EMA"]) / row["21EMA"] * 100
        conds = [
            ema_min <= gap_pct <= ema_max,
            atr_min <= row["ATR_pct"] <= atr_max,
            row["50SMA"] > row["150SMA"] > row["200SMA"],
            row["10SMA"] > row["21EMA"] > row["50SMA"],
            row["Vol50Avg"] >= vol_threshold,
        ]
        if not all(conds):
            continue

        results.append({
            "Ticker": tic,
            "Close": row["Close"],
            "EMA Gap%": round(gap_pct, 2),
            "ATR%": round(row["ATR_pct"], 2),
            "Vol50Avg": int(row["Vol50Avg"]),
        })

    prog.empty()
    st.success(f"„Çπ„ÇØ„É™„Éº„Éã„É≥„Ç∞ÂÆå‰∫ÜÔºö{len(results)} ‰ª∂„Éí„ÉÉ„Éà")

    if results:
        out = pd.DataFrame(results).sort_values("ATR%", ascending=False)
        st.dataframe(out, use_container_width=True)
        st.download_button("CSV„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ", out.to_csv(index=False).encode("utf-8"), "screened.csv")
        st.code(",".join(out["Ticker"].tolist()), language="text")
    else:
        st.warning("Êù°‰ª∂„Å´‰∏ÄËá¥„Åô„ÇãÈäòÊüÑ„Åå„ÅÇ„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
